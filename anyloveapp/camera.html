<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8" />
        <title>Camera Test</title>
        <script>
        if (navigator.mediaDevices?.getUserMedia) {
            console.log("camera access supported");
            //alert("camera access supported");
        }
        else {
            console.log("navigator.mediaDevices.getUserMedia() is not supported");
        }
        
        
        
    if (!navigator.mediaDevices?.enumerateDevices) {
        console.log("enumerateDevices() not supported.");
    }
    else
    {
        console.log("enumerateDevices supported");
        
        //List cameras and microphones
        navigator.mediaDevices
            .enumerateDevices()
            .then((devices) => {
                let audioSource = null;
                let videoSource = null;

                devices.forEach((device) => {
                console.log(device.kind);
                if (device.kind === "audioinput") {
                    audioSource = device.deviceId;
                } else if (device.kind === "videoinput") {
                    videoSource = device.deviceId;
                }
        });
        //sourceSelected(audioSource, videoSource);
    })
    .catch((err) => {
      console.error(`${err.name}: ${err.message}`);
    });
}

            /*
async function sourceSelected(audioSource, videoSource) {
  const constraints = {
    audio: { deviceId: audioSource },
    video: { deviceId: videoSource },
  };
  const stream = await navigator.mediaDevices.getUserMedia(constraints);
}
    }
    */
  
    // The width and height of the captured photo. We will set the
    // width to the value defined here, but the height will be
    // calculated based on the aspect ratio of the input stream.
    const width = 320; // We will scale the photo width to this
    let height = 0; // This will be computed based on the input stream

    // |streaming| indicates whether or not we're currently streaming
    // video from the camera. Obviously, we start at false.
    let streaming = false;

    // The various HTML elements we need to configure or control. These
    // will be set by the startup() function.
    let video = null;
    let canvas = null;
    let photo = null;
    let startButton = null;

  function startup() {
    //if (showViewLiveResultButton()) {
    //  return;
    //}
    video = document.getElementById("video");
    canvas = document.getElementById("canvas");
    photo = document.getElementById("photo");
    startButton = document.getElementById("start-button");

    navigator.mediaDevices
      .getUserMedia({ video: true, audio: false })
      .then((stream) => {
        video.srcObject = stream;
        video.play();
      })
      .catch((err) => {
        console.error(`An error occurred: ${err}`);
      });

    video.addEventListener(
      "canplay",
      (ev) => {
        if (!streaming) {
          height = video.videoHeight / (video.videoWidth / width);

          // Firefox currently has a bug where the height can't be read from
          // the video, so we will make assumptions if this happens.
          if (isNaN(height)) {
            height = width / (4 / 3);
          }

          video.setAttribute("width", width);
          video.setAttribute("height", height);
          canvas.setAttribute("width", width);
          canvas.setAttribute("height", height);
          streaming = true;
        }
      },
      false,
    );

    startButton.addEventListener(
      "click",
      (ev) => {
        takePicture();
        ev.preventDefault();
      },
      false,
    );

    clearPhoto();
  }

  // Fill the photo with an indication that none has been captured.
  function clearPhoto() {
    const context = canvas.getContext("2d");
    context.fillStyle = "#AAA";
    context.fillRect(0, 0, canvas.width, canvas.height);

    const data = canvas.toDataURL("image/png");
    photo.setAttribute("src", data);
  }

  // Capture a photo by fetching the current contents of the video
  // and drawing it into a canvas, then converting that to a PNG
  // format data URL. By drawing it on an offscreen canvas and then
  // drawing that to the screen, we can change its size and/or apply
  // other changes before drawing it.
  function takePicture() {
    const context = canvas.getContext("2d");
    if (width && height) {
      canvas.width = width;
      canvas.height = height;
      context.drawImage(video, 0, 0, width, height);

      const data = canvas.toDataURL("image/webp");
      photo.setAttribute("src", data);
        saveToBlob();
    } else {
      clearPhoto();
    }
  }
    
    function saveToBlob()
    {
        const canvas = document.getElementById("canvas");

canvas.toBlob((blob) => {
    const reader = new FileReader();
  const newImg = document.createElement("img");
  const url = URL.createObjectURL(blob);
    document.getElementById("divBlobSize").innerHTML = blob.size;
    document.getElementById("divBlobData").innerHTML = blob.text();


  newImg.src = url;
  document.body.appendChild(newImg);
});

        

    }
    

  // Set up our event listener to run the startup process
  // once loading is complete.
  window.addEventListener("load", startup, false);


        </script>
    </head>
    <body>
        <div class="content-area">
  <h1>Still photo capture demo</h1>
  <div class="camera">
    <video id="video">Video stream not available.</video>
    <button id="start-button">Take photo</button>
      <div id="divBlobSize"></div>
      <div id="divBlobData"></div>
  </div>
  <canvas id="canvas" style="display: none;"> </canvas>
  <div class="output">
    <img id="photo" src="" alt="The screen capture will appear in this box." />
  </div>
  <p>
    Credits
    <a
      href="https://developer.mozilla.org/en-US/docs/Web/API/Media_Capture_and_Streams_API/Taking_still_photos">
      Taking still photos with WebRTC
    </a>
  </p>
</div>
    </body>
</html>
